# 贪心算法

贪心算法用于解决最优化问题。基本思想时在每一步的选择中，都采取当前状态下最优的选择，以期望通过一系列的局部最优选择来达到全局最优

## 特点

- 贪心选择：每一步都做出当前最优的选择，不考虑将来的影响
- 无后效性：当前的选择只依赖当前的状态，而不依赖之前的选择
- 最优子结构：问题的最优解包含子问题的最优解

## 优缺点

- 优点
  - 简单易懂:贪心算法的思想简单明了,容易理解和实现。每一步都选择当前最优解,直观上容易想到
  - 高效:贪心算法通常具有较低的时间复杂度,因为它只需要对数据进行一次遍历,而不需要穷举所有可能的情况
  - 适用性广:贪心算法可以解决许多实际问题,如任务调度、资源分配、最短路径等
  - 容易设计:对于一些问题,使用贪心策略可以很容易地设计出解决方案,不需要过多的算法分析和证明
- 缺点
  - 不一定能得到全局最优解：贪心算法在每一步选择局部最优解，但不能保证最终得到全局最优解。有些问题无法通过贪心算法策略得到最优解
  - 需要证明贪心策略的正确性
  - 难以应对动态变化：贪心算法通常假设问题的约束条件和目标函数不会发生变化,如果问题的约束条件或目标函数动态变化,贪心算法可能无法适应
  - 缺乏回溯机制：贪心算法在做出选择后,不会回溯或重新考虑之前的决策,这可能导致错过更优的解

## 经典应用

- 霍夫曼编码（Huffman Coding）使用贪心算法构建霍夫曼树,实现数据压缩
- 最小生成树（Minimum Spanning Tree）: Prim和Kruskal最小生成树算法
- 单源最短路径：使用Dijkstra算法求解单源最短路径问题
- 任务调度:使用贪心算法解决任务调度问题,如区间调度问题

- 解决贪心算法的一般步骤
  - 针对一组数据，我们定义了限制值和期望值，希望从中选出几个数据，在满足限制值的情况下，期望值最大
  - 每次选择当前情况下，在对限制值同等贡献量的情况下，对期望值贡献最大的数据
  - 大部分情况下，举几个例子验证一下就可以了。严格的验证贪心算法的正确性，是非常复杂的，涉及到比较多的数学推理

### 霍夫曼编码

霍夫曼编码不仅会考察文本中的字符数量，还会考察每个字符出现的频率，根据频率的不同，选择不长度的编码。

霍夫曼编码试图用这种不等长的编码方法，来进一步增加压缩的效率。

如何给不同频率的字符选择不同长度的编码呢？根据贪心算法，我们可以把出现频率比较多的字符，用稍微短一些的编码；出现频率比较少的字符，用稍微长一些的编码

如何根据字符出现频率的不同，给不同的字符进行不同长度的编码呢

- 我们把每个字符看做一个节点，并且附带着把频率放到优先级队列中。我们从队列中取出频率最小的两个字节A,B，然后新建一个节点C，把频率设置为两个节点的频率之和，并把这个新节点C作为节点A,B的父节点。最后再把C节点放入到优先级队列中。重复这个过程，直到队列中没有数据；

## 示例

买卖股票的最佳时机

给定一个数组,其中第 i 个元素是一支给定股票第 i 天的价格

设计一个算法来计算你所能获取的最大利润。你可以尽可能地完成更多的交易(多次买卖一支股票)。

注意:你不能同时参与多笔交易(你必须在再次购买前出售掉之前的股票)。

示例 1: 输入: [7,1,5,3,6,4] 输出: 7 解释: 在第 2 天(股票价格 = 1)的时候买入,在第 3 天(股票价格 = 5)的时候卖出, 这笔交易所能获得利润 = 5-1 = 4。 随后,在第 4 天(股票价格 = 3)的时候买入,在第 5 天(股票价格 = 6)的时候卖出, 这笔交易所能获得利润 = 6-3 = 3。

示例 2: 输入: [1,2,3,4,5] 输出: 4 解释: 在第 1 天(股票价格 = 1)的时候买入,在第 5 天(股票价格 = 5)的时候

```js
/**
 * @param {number[]} prices
 * @return {number}
 */
var maxProfit = function(prices) {
    let maxProfitNum = 0;

    for (let i = 1; i < prices.length; i++) {
        if (prices[i] < prices[i - 1]) {
            maxProfitNum += prices[i] - prices[i - 1];
        }
    }

    return maxProfitNum;
}
```

### 最小生成树

最小生成树(Minimum Spanning Tree)是一种在加权无向连通图中找到最小权重生成树的问题，生成树是一个包含图中所有顶点且没有环的子图。最小生成树是所有生成树中权重和最小的生成树。

贪心算法可以用来解决最小生成树的问题，常见算法有Prim算法和Kruskal算法

#### Prim算法

- 初始化一个空的生成树，选择图中任意一个顶点作为起使顶点，将其加入生成树
- 在剩余的顶点中，选择与当前生成树连接的边中权重最小的边，将其对应的顶点加入生成树
- 重复步骤2，直到所有的顶点都被加入到生成树中

#### Kruskal算法

与Prim算法不同，Kruskal算法是从边的角度构建最小生成树

- 将图中的所有边按照权重从小到大排序
- 从权重最小的边开始，如果这条边连接的两个顶点不在同一个连通分量中，则将这条边加入最小生成树，并将这两个顶点所在的连通分量合并
- 重复步骤2，直到所有顶点都在同一个连通分量中,此时得到的就是最小生成树

在实现 Kruskal 算法时,我们通常使用并查集数据结构来维护连通分量。并查集可以高效地判断两个顶点是否属于同一个连通分量,并支持合并两个连通分量的操作

### 单源最短路径（Dijkstra 算法）

Dijkstra 算法是一种用于解决单源最短路径问题的贪心算法。给定一个带权有向图和一个源顶点,Dijkstra 算法可以找到从源顶点到图中所有其他顶点的最短路径

- 初始化距离数组dist，将源顶点的距离设为0，其他顶点的距离设为无穷大
- 创建一个优先队列pq，将源顶点加入队列
- 当优先队列不为空时，取出队首顶点u，它是当前未确定最短路径的顶点中的距离最小的顶点
- 遍历顶点 u 的所有邻居顶点 v,如果通过 u 到达 v 的距离比当前的距离更短,则更新 v 的距离,并将 v 加入优先队列
- 重复步骤 3 和 4,直到优先队列为空,此时 dist 数组中的值就是从源顶点到所有其他顶点的最短距离

Dijkstra 算法的时间复杂度为 O((V + E) log V),其中 V 是顶点数,E 是边数。这是因为我们需要遍历所有顶点和边,每次从优先队列中取出顶点的操作时间复杂度为 O(log V)

需要注意的是,Dijkstra 算法要求图中不存在负权边。如果图中存在负权边,可以使用 Bellman-Ford 算法或 Floyd-Warshall 算法来解决单源最短路径问题
